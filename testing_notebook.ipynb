{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e774d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_int_from_string(input_string):\n",
    "    # Use a regular expression to find the number in the string\n",
    "    match = re.search(r'\\d[\\d,]*', input_string)\n",
    "    if match:\n",
    "        # Remove commas and convert to integer\n",
    "        number = int(match.group().replace(',', ''))\n",
    "        return number\n",
    "    return None\n",
    "\n",
    "\n",
    "def name_to_id(artist_name):\n",
    "    artist_dict = {\"Azahriah\":\"6EIriUxo7vznEgJtTDlXpq?si=iThY86mXTe28gVdZy7jNTA\"}\n",
    "    try:\n",
    "        artist_id  = artist_dict[artist_name]\n",
    "        return artist_id\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Artist '{artist_name}' not in database\")\n",
    "\n",
    "\n",
    "\n",
    "def get_spotify_listeners(artist_name):\n",
    "    \n",
    "    artist_id = name_to_id(artist_name)\n",
    "    \n",
    "    # Get artist page from Spotify\n",
    "    artist_url = f\"https://open.spotify.com/artist/{artist_id}\"\n",
    "    response = requests.get(artist_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch artist page for {artist_name}. Status code: {response.status_code}\")\n",
    "    \n",
    "    # Parse the artist's page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the monthly listeners\n",
    "    monthly_listeners = soup.find('div', {'data-testid': 'monthly-listeners-label'}).text\n",
    "    \n",
    "    monthly_listeners = extract_int_from_string(monthly_listeners)\n",
    "    \n",
    "    if not monthly_listeners:\n",
    "        print(f\"Monthly listeners not found for {artist_name}.\")\n",
    "        return None\n",
    "    \n",
    "    return monthly_listeners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7565ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2986c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new artist Moriones to data and resetting today's values\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from get_monthly_listeners import get_spotify_listeners\n",
    "from datetime import datetime\n",
    "\n",
    "def add_listeners_to_csv(json_file='artist_db.json', csv_file='listeners_data.csv'):\n",
    "    # Load the dictionary from the JSON file\n",
    "    with open(json_file, 'r') as file:\n",
    "        artist_dict = json.load(file)\n",
    "    \n",
    "    # Read the existing CSV file into a DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, create an empty DataFrame with the correct columns\n",
    "        df = pd.DataFrame(columns=['Date'] + list(artist_dict.keys()))\n",
    "\n",
    "    \n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Check if the current date is already in the DataFrame\n",
    "    if current_date in df['Date'].values:\n",
    "        if set(df.columns) == set(list(artist_dict.keys()) + ['Date']):\n",
    "            print(\"Stock data up to date\")\n",
    "            return\n",
    "        \n",
    "        df = df[df['Date'] != current_date]\n",
    "    \n",
    "        # Check for missing artist columns and add them with NaN values\n",
    "        for artist_name in artist_dict.keys():\n",
    "            if artist_name not in df.columns:\n",
    "                print(f\"Adding new artist {artist_name} to data and resetting today's values\")\n",
    "                df[artist_name] = pd.Series([float('nan')] * len(df))\n",
    "    \n",
    "    # Create a dictionary to hold the new row of data\n",
    "    new_row = {'Date': current_date}\n",
    "\n",
    "    # Iterate through the dictionary keys\n",
    "    for artist_name in artist_dict.keys():\n",
    "        # Call the get_spotify_listeners function and store the result\n",
    "        listeners = get_spotify_listeners(artist_name)\n",
    "        new_row[artist_name] = listeners\n",
    "    \n",
    "    # Append the new row to the DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "def main():\n",
    "    add_listeners_to_csv()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5dd3b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Azahriah</th>\n",
       "      <th>Pogány Induló</th>\n",
       "      <th>Elefánt</th>\n",
       "      <th>Moriones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>700135</td>\n",
       "      <td>356819</td>\n",
       "      <td>114427</td>\n",
       "      <td>203364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Azahriah  Pogány Induló  Elefánt  Moriones\n",
       "0  2024-07-30    700135         356819   114427    203364"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"listeners_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5c79c5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 13\u001b[0m, in \u001b[0;36madd_listeners_to_csv\u001b[0;34m(json_file, csv_file)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# If the file does not exist, create an empty DataFrame with the correct columns\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m         handle,\n\u001b[1;32m    861\u001b[0m         ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m         newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'listeners_data.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19411/1606631401.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Save the updated DataFrame to the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0madd_listeners_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_19411/1606631401.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(json_file, csv_file)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# If the file does not exist, create an empty DataFrame with the correct columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Initialize with a row that has NaN for each column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Check for missing artist columns and add them with NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0martist_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martist_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from get_monthly_listeners import get_spotify_listeners\n",
    "from datetime import datetime\n",
    "\n",
    "def add_listeners_to_csv(json_file='artist_db.json', csv_file='listeners_data.csv'):\n",
    "    # Load the dictionary from the JSON file\n",
    "    with open(json_file, 'r') as file:\n",
    "        artist_dict = json.load(file)\n",
    "    \n",
    "    # Read the existing CSV file into a DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, create an empty DataFrame with the correct columns\n",
    "        columns = ['Date'] + list(artist_dict.keys())\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "        # Initialize with a row that has NaN for each column\n",
    "        df = df.append(pd.Series([float('nan')] * len(columns), index=columns), ignore_index=True)\n",
    "\n",
    "    # Check for missing artist columns and add them with NaN values\n",
    "    for artist_name in artist_dict.keys():\n",
    "        if artist_name not in df.columns:\n",
    "            df[artist_name] = pd.Series([float('nan')] * len(df))\n",
    "\n",
    "    # Create a dictionary to hold the new row of data\n",
    "    new_row = {'Date': datetime.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "    # Iterate through the dictionary keys\n",
    "    for artist_name in artist_dict.keys():\n",
    "        # Call the get_spotify_listeners function and store the result\n",
    "        listeners = get_spotify_listeners(artist_name)\n",
    "        new_row[artist_name] = listeners\n",
    "    \n",
    "    # Append the new row to the DataFrame\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Example usage\n",
    "add_listeners_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d8a3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "users_file = 'users.json'\n",
    "listeners_file = './data/listeners_data.csv'\n",
    "\n",
    "# Load JSON data\n",
    "def load_users():\n",
    "    try:\n",
    "        with open(users_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "# Save JSON data\n",
    "def save_users(users):\n",
    "    with open(users_file, 'w') as f:\n",
    "        json.dump(users, f, indent=4)\n",
    "\n",
    "# Add user\n",
    "def add_user(username):\n",
    "    users = load_users()\n",
    "    if username not in users:\n",
    "        users[username] = {\n",
    "            'Username': username,\n",
    "            'Stocks': [],\n",
    "            'FloatingMoney': 100,\n",
    "            'PortfolioValue': 100\n",
    "        }\n",
    "        save_users(users)\n",
    "        print(f\"User {username} added successfully.\")\n",
    "    else:\n",
    "        print(f\"User {username} already exists.\")\n",
    "\n",
    "# Calculate Portfolio\n",
    "def calculate_portfolio(username):\n",
    "    users = load_users()\n",
    "    if username in users:\n",
    "        df = pd.read_csv(listeners_file)\n",
    "        last_row = df.iloc[-1]\n",
    "        portfolio_value = 0\n",
    "        \n",
    "        for stock in users[username]['Stocks']:\n",
    "            artist_name = stock['ArtistName']\n",
    "            current_gross = last_row[artist_name]\n",
    "            stock['CurrentValue'] = (current_gross / stock['GrossAtPurchase']) * stock['AmountPurchased']\n",
    "            portfolio_value += stock['CurrentValue']\n",
    "        \n",
    "        users[username]['PortfolioValue'] = portfolio_value\n",
    "        save_users(users)\n",
    "        print(f\"Portfolio for {username} updated successfully.\")\n",
    "    else:\n",
    "        print(f\"User {username} not found.\")\n",
    "\n",
    "# Buy stock\n",
    "def buy_stock(username, artist_name, amount_purchased):\n",
    "    users = load_users()\n",
    "    if username in users:\n",
    "        df = pd.read_csv(listeners_file)\n",
    "        last_row = df.iloc[-1]\n",
    "        \n",
    "        if users[username]['FloatingMoney'] >= amount_purchased:\n",
    "            current_gross = last_row[artist_name]\n",
    "            stock_exists = False\n",
    "            \n",
    "            for stock in users[username]['Stocks']:\n",
    "                if stock['ArtistName'] == artist_name:\n",
    "                    stock['AmountPurchased'] += amount_purchased\n",
    "                    stock['GrossAtPurchase'] = current_gross\n",
    "                    stock_exists = True\n",
    "                    break\n",
    "            \n",
    "            if not stock_exists:\n",
    "                new_stock = {\n",
    "                    'ArtistName': artist_name,\n",
    "                    'CurrentValue': amount_purchased,  # Will be updated in calculate_portfolio\n",
    "                    'AmountPurchased': amount_purchased,\n",
    "                    'GrossAtPurchase': int(current_gross)\n",
    "                }\n",
    "                users[username]['Stocks'].append(new_stock)\n",
    "            \n",
    "            users[username]['FloatingMoney'] -= amount_purchased\n",
    "            calculate_portfolio(username)\n",
    "            save_users(users)\n",
    "            print(f\"Stock {artist_name} purchased successfully for user {username}.\")\n",
    "        else:\n",
    "            print(\"Insufficient funds.\")\n",
    "    else:\n",
    "        print(f\"User {username} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b2c404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User johndoe added successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "add_user('johndoe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a8a60c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio for johndoe updated successfully.\n",
      "Stock Elefánt purchased successfully for user johndoe.\n"
     ]
    }
   ],
   "source": [
    "buy_stock('johndoe', 'Elefánt', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ddad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_portfolio('johndoe')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
